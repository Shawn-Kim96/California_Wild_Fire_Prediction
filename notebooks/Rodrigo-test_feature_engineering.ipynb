{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cdebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d48536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "current_path = os.path.abspath('.')\n",
    "root_path = None\n",
    "\n",
    "while current_path != \"/\":\n",
    "    if os.path.exists(os.path.join(current_path, \"data\", \"final_data\", \"total_data.csv\")):\n",
    "        root_path = current_path\n",
    "        break\n",
    "    current_path = os.path.dirname(current_path)\n",
    "\n",
    "if root_path is None:\n",
    "    raise FileNotFoundError(\"Could not find project root.\")\n",
    "\n",
    "sys.path.append(os.path.join(root_path, 'src', 'dataset_preprocess'))\n",
    "\n",
    "# Now import your feature engineering functions\n",
    "from feature_engineering_functions import (\n",
    "    add_min_max_quantile_features,\n",
    "    add_trend_diff_features,\n",
    "    add_extreme_event_flags,\n",
    "    add_interaction_features,\n",
    "    add_rolling_std_features,\n",
    "    add_ratio_features,\n",
    "    add_cumulative_climate_load,\n",
    "    add_soil_dryness_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17feb91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map feature engineering functions\n",
    "feature_engineering_functions = {\n",
    "    'MinMaxQuantile': add_min_max_quantile_features,\n",
    "    'TrendDiff': add_trend_diff_features,\n",
    "    'ExtremeFlags': add_extreme_event_flags,\n",
    "    'InteractionFeatures': add_interaction_features,\n",
    "    'StdFeatures': add_rolling_std_features,\n",
    "    'RatioFeatures': add_ratio_features,\n",
    "    'CumulativeLoad': add_cumulative_climate_load,\n",
    "    'SoilDrynessIndex': add_soil_dryness_index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130ad800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "data_path = os.path.join(root_path, 'data', 'final_data', 'total_data.csv')\n",
    "df_base = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c2c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa36c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training with feature set: MinMaxQuantile ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     41\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred)\n\u001b[0;32m---> 42\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m(y_test, y_prob) \u001b[38;5;28;01mif\u001b[39;00m y_prob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     44\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatureSet\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_name,\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m: auc\n\u001b[1;32m     50\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "for feature_name, feature_function in feature_engineering_functions.items():\n",
    "    print(f\"=== Training with feature set: {feature_name} ===\")\n",
    "    df = df_base.copy()\n",
    "\n",
    "    # Drop leakage columns\n",
    "    drop_cols = ['burn_probability', 'conditional_flame_length', 'conditional_risk_to_structures',\n",
    "                 'distance_km', 'exposure', 'flame_length_exceedance_4ft', 'flame_length_exceedance_8ft',\n",
    "                 'wildfire_hazard_potential', 'risk_to_structures', 'acres_burned', 'CBD_VALUE',\n",
    "                 'EVC_VALUE', 'FBFM_VALUE', 'FDIST_VALUE', 'FVC_VALUE', 'Unnamed: 0', 'lat', 'lng']\n",
    "    df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "\n",
    "    # Apply feature engineering\n",
    "    df = feature_function(df)\n",
    "\n",
    "    # Label\n",
    "    y = df['is_fire']\n",
    "    X = df.drop(columns=['is_fire', 'date', 'latitude', 'longitude'], errors='ignore')\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Drop rows with NaN after feature engineering\n",
    "    X = X.dropna()\n",
    "    y = y.loc[X.index]\n",
    "\n",
    "    # Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "\n",
    "        results.append({\n",
    "            'FeatureSet': feature_name,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': acc,\n",
    "            'F1 Score': f1,\n",
    "            'AUC': auc\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef3c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Performance Summary ===\n",
      "             FeatureSet                Model  Accuracy  F1 Score\n",
      "0        MinMaxQuantile  Logistic Regression   0.51250  0.540094\n",
      "1        MinMaxQuantile        Random Forest   0.50750  0.486979\n",
      "2        MinMaxQuantile        Decision Tree   0.52000  0.520000\n",
      "3        MinMaxQuantile    Gradient Boosting   0.46750  0.480488\n",
      "4        MinMaxQuantile              XGBoost   0.50125  0.495575\n",
      "5             TrendDiff  Logistic Regression   0.51125  0.543757\n",
      "6             TrendDiff        Random Forest   0.49500  0.488608\n",
      "7             TrendDiff        Decision Tree   0.50625  0.500632\n",
      "8             TrendDiff    Gradient Boosting   0.49250  0.500000\n",
      "9             TrendDiff              XGBoost   0.50250  0.501253\n",
      "10         ExtremeFlags  Logistic Regression   0.51750  0.546948\n",
      "11         ExtremeFlags        Random Forest   0.49625  0.506732\n",
      "12         ExtremeFlags        Decision Tree   0.52000  0.508951\n",
      "13         ExtremeFlags    Gradient Boosting   0.49625  0.504305\n",
      "14         ExtremeFlags              XGBoost   0.51875  0.499350\n",
      "15  InteractionFeatures  Logistic Regression   0.51000  0.558559\n",
      "16  InteractionFeatures        Random Forest   0.48125  0.476671\n",
      "17  InteractionFeatures        Decision Tree   0.52250  0.497368\n",
      "18  InteractionFeatures    Gradient Boosting   0.51250  0.525547\n",
      "19  InteractionFeatures              XGBoost   0.48750  0.481013\n",
      "20          StdFeatures  Logistic Regression   0.51000  0.554545\n",
      "21          StdFeatures        Random Forest   0.48625  0.489441\n",
      "22          StdFeatures        Decision Tree   0.51250  0.507576\n",
      "23          StdFeatures    Gradient Boosting   0.48125  0.496970\n",
      "24          StdFeatures              XGBoost   0.48750  0.481013\n",
      "25        RatioFeatures  Logistic Regression   0.52125  0.559264\n",
      "26        RatioFeatures        Random Forest   0.49250  0.504878\n",
      "27        RatioFeatures        Decision Tree   0.49500  0.492462\n",
      "28        RatioFeatures    Gradient Boosting   0.52000  0.523573\n",
      "29        RatioFeatures              XGBoost   0.48875  0.491925\n",
      "30       CumulativeLoad  Logistic Regression   0.50375  0.559378\n",
      "31       CumulativeLoad        Random Forest   0.47500  0.478908\n",
      "32       CumulativeLoad        Decision Tree   0.52500  0.509044\n",
      "33       CumulativeLoad    Gradient Boosting   0.51750  0.523457\n",
      "34       CumulativeLoad              XGBoost   0.47750  0.480100\n",
      "35     SoilDrynessIndex  Logistic Regression   0.49000  0.540541\n",
      "36     SoilDrynessIndex        Random Forest   0.50625  0.492940\n",
      "37     SoilDrynessIndex        Decision Tree   0.49750  0.488550\n",
      "38     SoilDrynessIndex    Gradient Boosting   0.51000  0.521951\n",
      "39     SoilDrynessIndex              XGBoost   0.50875  0.514215\n"
     ]
    }
   ],
   "source": [
    "# Show Results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Model Performance Summary ===\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
